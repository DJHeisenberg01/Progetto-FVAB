{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import my_utility as mu\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "import keras.ops as K\n",
    "from keras.losses import MeanSquaredError\n",
    "from scipy.spatial.distance import cityblock, canberra, hamming, chebyshev, braycurtis, mahalanobis, cosine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Parametri della rete\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "margin = 1  # Margin for contrastive loss.\n",
    "\n",
    "n = 384 # Dimensione codifica frattale\n",
    "\n",
    "# Parametri del dataset\n",
    "num_samples_train = 8000\n",
    "num_samples_val = 2000\n",
    "num_samples_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 128, 128])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2000, 128, 128])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2000, 128, 128])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione\n",
    "target_distances = np.zeros(num_samples_train)\n",
    "val_target_distances=np.zeros(num_samples_val)\n",
    "\n",
    "# Path cartelle dei file\n",
    "dir_codify = r'.\\img_celeba_10000'\n",
    "dir_images_train = dir_codify + r'\\img_celeba_10000_train'\n",
    "dir_images_val = dir_codify + r'\\img_celeba_10000_valid'\n",
    "dir_image_test = dir_codify + r'\\img_celeba_2000_test'\n",
    "\n",
    "# Caricamento di immagini ed embeddings\n",
    "train_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_train.csv', num_samples_train)\n",
    "val_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_valid.csv', num_samples_val)\n",
    "test_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_2000_test.csv', num_samples_test)\n",
    "train_images = mu.image_loader(dir_images_train)\n",
    "val_images = mu.image_loader(dir_images_val)\n",
    "test_images = mu.image_loader(dir_image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 384), dtype=float32, sparse=False, name=keras_tensor_97>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m embedding_network \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(input_image, x)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Chiamo la rete che genera l'embedding sull'immagine in input\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# Definizione degli input della siamese\n",
    "input_image = keras.layers.Input((128, 128, 1))\n",
    "input_embedding = keras.layers.Input((384,))\n",
    "\n",
    "# Ramo CNN della siamese per l'immagine\n",
    "x = keras.layers.BatchNormalization()(input_image)\n",
    "x = keras.layers.Conv2D(4, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Conv2D(16, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(n, activation = \"tanh\")(x)\n",
    "embedding_network = keras.Model(input_image, x)\n",
    "\n",
    "# Chiamo la rete che genera l'embedding sull'immagine in input\n",
    "tower_image = embedding_network(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.euclidean_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.manhattan_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canberra distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.canberra_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.hamming_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.chebyshev_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bray Curtis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.bray_curtis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.mahalanobis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.cosine_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge layer\n",
    "siamese = keras.Model(inputs=[input_image, input_embedding], outputs=merge_layer)\n",
    "\n",
    "# Learning rate personalizzato (opzionale)\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps = 10000, decay_rate = 0.9, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "\n",
    "# Chiamata alla loss personalizzata in my utility\n",
    "siamese.compile(optimizer=optimizer, loss=mu.loss(margin = margin))\n",
    "\n",
    "# Chiamata ad una loss di keras\n",
    "#siamese.compile(optimizer=optimizer, loss=MeanSquaredError)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica e conversione dei dati per la rete\n",
    "train_images = np.array(train_images, dtype = np.float32)\n",
    "train_embeddings = np.array(train_embeddings, dtype = np.float32)\n",
    "\n",
    "val_images = np.array(val_images, dtype = np.float32)\n",
    "val_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "test_images = np.array(val_images, dtype = np.float32)\n",
    "test_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "# Assicurati che le etichette abbiano la stessa lunghezza del numero di campioni di addestramento\n",
    "assert len(train_embeddings) == num_samples_train, \"Errore: Lunghezza delle etichette non corrispondente al numero di campioni di addestramento.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento\n",
    "history = siamese.fit([train_images, train_embeddings], train_embeddings, epochs = epochs, batch_size = batch_size,\n",
    "                      validation_data=([val_images, val_embeddings], val_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.save(\"my_model.keras\", overwrite=True) #Cambia nome in base alla distanza da calcolare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione della rete\n",
    "eval_result = siamese.evaluate([test_images, test_embeddings], test_embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function for a test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di test per il calcolo delle distanze\n",
    "example_index = 0\n",
    "test_image = np.expand_dims(test_images[example_index], axis = 0)\n",
    "test_embedding = np.expand_dims(test_embeddings[example_index], axis = 0)\n",
    "predicted_embedding = siamese.predict([test_image, test_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo della distanza Euclidea in numpy\n",
    "euclidean_distance = np.linalg.norm(test_embedding - predicted_embedding)\n",
    "print(f\"Distanza Euclidea per l'immagine di test: {euclidean_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo della distanza di Manhattan\n",
    "manhattan_dist = cityblock(test_embedding, predicted_embedding)\n",
    "print(f\"Distanza di Manhattan per l'immagine di test: {manhattan_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canberra Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canberra_distance = canberra(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Canberra tra test_embedding e predicted_embedding:\", canberra_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_dist = hamming(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Hamming tra test_embedding e predicted_embedding:\", hamming_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev_dist = chebyshev(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Chebyshev tra test_embedding e predicted_embedding:\", chebyshev_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bray Curtis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "braycurtis_dist = braycurtis(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Bray Curtis tra test_embedding e predicted_embedding:\", braycurtis_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_dist = mahalanobis(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Mahalanobis tra test_embedding e predicted_embedding:\", mahalanobis_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_dist = cosine(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Cosine tra test_embedding e predicted_embedding:\", cosine_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione della curva di apprendimento\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
