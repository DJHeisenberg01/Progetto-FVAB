{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import my_utility as mu\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "import keras.ops as K\n",
    "from keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Parametri della rete\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "margin = 1  # Margin for contrastive loss.\n",
    "\n",
    "n = 384 # Dimensione codifica frattale\n",
    "\n",
    "# Parametri del dataset\n",
    "num_samples_train = 8000\n",
    "num_samples_val = 2000\n",
    "num_samples_test = 2000\n",
    "\n",
    "\n",
    "# Inizializzazione\n",
    "target_distances = np.zeros(num_samples_train)\n",
    "val_target_distances=np.zeros(num_samples_val)\n",
    "\n",
    "# Path cartelle dei file\n",
    "dir_codify = r'.\\img_celeba_10000'\n",
    "dir_images_train = dir_codify + r'\\img_celeba_10000_train'\n",
    "dir_images_val = dir_codify + r'\\img_celeba_10000_valid'\n",
    "dir_image_test = dir_codify + r'\\img_celeba_2000_test'\n",
    "\n",
    "# Path di immagini ed embeddings\n",
    "train_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_train.csv', num_samples_train)\n",
    "val_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_valid.csv', num_samples_val)\n",
    "test_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_2000_test.csv', num_samples_test)\n",
    "train_images = mu.image_loader(dir_images_train)\n",
    "val_images = mu.image_loader(dir_images_val)\n",
    "test_images = mu.image_loader(dir_image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definizione degli input della siamese\n",
    "input_image = keras.layers.Input((128, 128, 1))\n",
    "input_embedding = keras.layers.Input((384,))\n",
    "\n",
    "# Ramo CNN della siamese per l'immagine\n",
    "x = keras.layers.BatchNormalization()(input_image)\n",
    "x = keras.layers.Conv2D(4, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Conv2D(16, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(n, activation = \"tanh\")(x)\n",
    "embedding_network = keras.Model(input_image, x)\n",
    "\n",
    "# Chiamo la rete che genera l'embedding sull'immagine in input\n",
    "tower_image = embedding_network(input_image)\n",
    "\n",
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.euclidean_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")\n",
    "\n",
    "# Merge layer\n",
    "siamese = keras.Model(inputs=[input_image, input_embedding], outputs=merge_layer)\n",
    "\n",
    "# Learning rate personalizzato (opzionale)\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps = 10000, decay_rate = 0.9, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "\n",
    "# Chiamata alla loss personalizzata in my utility\n",
    "siamese.compile(optimizer=optimizer, loss=mu.loss(margin = margin))\n",
    "\n",
    "# Chiamata ad una loss di keras\n",
    "# Siamese.compile(optimizer=optimizer, loss=MeanSquaredError)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica e conversione dei dati per la rete\n",
    "train_images = np.array(train_images, dtype = np.float32)\n",
    "train_embeddings = np.array(train_embeddings, dtype = np.float32)\n",
    "\n",
    "val_images = np.array(val_images, dtype = np.float32)\n",
    "val_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "test_images = np.array(val_images, dtype = np.float32)\n",
    "test_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "# Assicurati che le etichette abbiano la stessa lunghezza del numero di campioni di addestramento\n",
    "assert len(train_embeddings) == num_samples_train, \"Errore: Lunghezza delle etichette non corrispondente al numero di campioni di addestramento.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento\n",
    "history = siamese.fit([train_images, train_embeddings], train_embeddings, epochs = epochs, batch_size = batch_size,\n",
    "                      validation_data=([val_images, val_embeddings], val_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione della rete\n",
    "eval_result = siamese.evaluate([test_images, test_embeddings], test_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function for a test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcolo della distanza Euclidea per un esempio di test\n",
    "example_index = 0\n",
    "test_image = np.expand_dims(test_images[example_index], axis = 0)\n",
    "test_embedding = np.expand_dims(test_embeddings[example_index], axis = 0)\n",
    "predicted_embedding = siamese.predict([test_image, test_embedding])\n",
    "\n",
    "# Calcolo della distanza Euclidea in numpy\n",
    "euclidean_distance = np.linalg.norm(test_embedding - predicted_embedding)\n",
    "\n",
    "print(f\"Distanza Euclidea per l'immagine di test: {euclidean_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione della curva di apprendimento\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Progetto-FVAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
