{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import my_utility as mu\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "import keras.ops as K\n",
    "from keras.losses import MeanSquaredError\n",
    "from scipy.spatial.distance import cityblock, canberra, hamming, chebyshev, braycurtis, mahalanobis, cosine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Parametri della rete\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "margin = 1  # Margin for contrastive loss.\n",
    "\n",
    "n = 384 # Dimensione codifica frattale\n",
    "\n",
    "# Parametri del dataset\n",
    "num_samples_train = 8000\n",
    "num_samples_val = 2000\n",
    "num_samples_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 128, 128])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2000, 128, 128])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2000, 128, 128])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Inizializzazione\n",
    "target_distances = np.zeros(num_samples_train)\n",
    "val_target_distances=np.zeros(num_samples_val)\n",
    "\n",
    "# Path cartelle dei file\n",
    "dir_codify = r'.\\img_celeba_10000'\n",
    "dir_images_train = dir_codify + r'\\img_celeba_10000_train'\n",
    "dir_images_val = dir_codify + r'\\img_celeba_10000_valid'\n",
    "dir_image_test = dir_codify + r'\\img_celeba_2000_test'\n",
    "\n",
    "# Caricamento di immagini ed embeddings\n",
    "train_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_train.csv', num_samples_train)\n",
    "val_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_10000_valid.csv', num_samples_val)\n",
    "test_embeddings = mu.open_csv(dir_codify, '\\codify_celeba_2000_test.csv', num_samples_test)\n",
    "train_images = mu.image_loader(dir_images_train)\n",
    "val_images = mu.image_loader(dir_images_val)\n",
    "test_images = mu.image_loader(dir_image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 14,
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "<class 'keras.src.backend.common.keras_tensor.KerasTensor'>\n",
      "<class 'keras.src.backend.common.keras_tensor.KerasTensor'>\n"
=======
      "<KerasTensor shape=(None, 384), dtype=float32, sparse=False, name=keras_tensor_97>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(n, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m embedding_network \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(input_image, x)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Chiamo la rete che genera l'embedding sull'immagine in input\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
     ]
    }
   ],
   "source": [
    "# Definizione degli input della siamese\n",
    "input_image = keras.layers.Input((128, 128, 1))\n",
    "input_embedding = keras.layers.Input((384,))\n",
    "\n",
    "# Ramo CNN della siamese per l'immagine\n",
    "x = keras.layers.BatchNormalization()(input_image)\n",
    "x = keras.layers.Conv2D(4, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Conv2D(16, (5, 5), activation = \"tanh\")(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(n, activation = \"tanh\")(x)\n",
    "embedding_network = keras.Model(input_image, x)\n",
    "\n",
    "# Chiamo la rete che genera l'embedding sull'immagine in input\n",
    "tower_image = embedding_network(input_image)\n",
    "print(type(tower_image))\n",
    "\n",
    "print(type(input_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.euclidean_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.manhattan_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canberra distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.canberra_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.hamming_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.chebyshev_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bray Curtis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.bray_curtis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.mahalanobis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.cosine_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "# Merge dell'Embedding generato dalla CNN con l'embedding in input\n",
    "merge_layer = keras.layers.Lambda(mu.manhattan_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canberra distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.canberra_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.hamming_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.chebyshev_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bray Curtis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.bray_curtis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.mahalanobis_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = keras.layers.Lambda(mu.cosine_distance, output_shape = (1,))(\n",
    "    [tower_image, input_embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
    "# Merge layer\n",
    "siamese = keras.Model(inputs=[input_image, input_embedding], outputs=merge_layer)\n",
    "\n",
    "# Learning rate personalizzato (opzionale)\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps = 10000, decay_rate = 0.9, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "\n",
    "# Chiamata alla loss personalizzata in my utility\n",
    "siamese.compile(optimizer=optimizer, loss=mu.loss(margin = margin))\n",
    "\n",
    "# Chiamata ad una loss di keras\n",
    "#siamese.compile(optimizer=optimizer, loss=MeanSquaredError)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica e conversione dei dati per la rete\n",
    "train_images = np.array(train_images, dtype = np.float32)\n",
    "train_embeddings = np.array(train_embeddings, dtype = np.float32)\n",
    "\n",
    "val_images = np.array(val_images, dtype = np.float32)\n",
    "val_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "test_images = np.array(val_images, dtype = np.float32)\n",
    "test_embeddings = np.array(val_embeddings, dtype = np.float32)\n",
    "\n",
    "# Assicurati che le etichette abbiano la stessa lunghezza del numero di campioni di addestramento\n",
    "assert len(train_embeddings) == num_samples_train, \"Errore: Lunghezza delle etichette non corrispondente al numero di campioni di addestramento.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\Desktop\\Progetto-FVAB\\.conda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - loss: -3275740.5000 - val_loss: -4682742.5000\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -4024899.0000 - val_loss: -4716643.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -3909147.7500 - val_loss: -4712506.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -4027057.2500 - val_loss: -4702396.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -3856687.5000 - val_loss: -4703846.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -4096234.7500 - val_loss: -4703719.5000\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -3941793.0000 - val_loss: -4709976.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -4183948.2500 - val_loss: -4700111.5000\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -4191144.2500 - val_loss: -4696515.5000\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - loss: -3947163.2500 - val_loss: -4710317.0000\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "source": [
    "# Addestramento\n",
    "history = siamese.fit([train_images, train_embeddings], train_embeddings, epochs = epochs, batch_size = batch_size,\n",
    "                      validation_data=([val_images, val_embeddings], val_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.save(\"my_model.keras\", overwrite=True) #Cambia nome in base alla distanza da calcolare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: -4616091.0000\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "source": [
    "# Valutazione della rete\n",
    "eval_result = siamese.evaluate([test_images, test_embeddings], test_embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function for a test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# Esempio di test per il calcolo delle distanze\n",
    "example_index = 0\n",
    "test_image = np.expand_dims(test_images[example_index], axis = 0)\n",
    "test_embedding = np.expand_dims(test_embeddings[example_index], axis = 0)\n",
    "predicted_embedding = siamese.predict([test_image, test_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanza Euclidea per l'immagine di test: 8655.689453125\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 2e2d1d435bd9c1b3f87ddf13b29768619c4009b9
   "source": [
    "# Calcolo della distanza Euclidea in numpy\n",
    "euclidean_distance = np.linalg.norm(test_embedding - predicted_embedding)\n",
    "print(f\"Distanza Euclidea per l'immagine di test: {euclidean_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanza di Manhattan per l'immagine di test: 130807.015625\n"
     ]
    }
   ],
   "source": [
    "# Calcolo della distanza di Manhattan\n",
    "manhattan_dist = cityblock(test_embedding.flatten(), predicted_embedding.flatten())\n",
    "print(f\"Distanza di Manhattan per l'immagine di test: {manhattan_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canberra Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanza di Canberra tra test_embedding e predicted_embedding: 319.9458630213506\n"
     ]
    }
   ],
   "source": [
    "canberra_distance = canberra(test_embedding.flatten(), predicted_embedding.flatten())\n",
    "print(\"Distanza di Canberra tra test_embedding e predicted_embedding:\", canberra_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 1d arrays must have equal lengths.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hamming_dist \u001b[38;5;241m=\u001b[39m \u001b[43mhamming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistanza di Hamming tra test_embedding e predicted_embedding:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hamming_dist)\n",
      "File \u001b[1;32mc:\\Users\\antho\\Desktop\\Progetto-FVAB\\.conda\\lib\\site-packages\\scipy\\spatial\\distance.py:745\u001b[0m, in \u001b[0;36mhamming\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    743\u001b[0m v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m v\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe 1d arrays must have equal lengths.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    746\u001b[0m u_ne_v \u001b[38;5;241m=\u001b[39m u \u001b[38;5;241m!=\u001b[39m v\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The 1d arrays must have equal lengths."
     ]
    }
   ],
   "source": [
    "\n",
    "hamming_dist = hamming(test_embedding.flatten(), predicted_embedding.flatten())\n",
    "print(\"Distanza di Hamming tra test_embedding e predicted_embedding:\", hamming_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev_dist = chebyshev(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Chebyshev tra test_embedding e predicted_embedding:\", chebyshev_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bray Curtis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "braycurtis_dist = braycurtis(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Bray Curtis tra test_embedding e predicted_embedding:\", braycurtis_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_dist = mahalanobis(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Mahalanobis tra test_embedding e predicted_embedding:\", mahalanobis_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_dist = cosine(test_embedding, predicted_embedding)\n",
    "print(\"Distanza di Cosine tra test_embedding e predicted_embedding:\", cosine_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione della curva di apprendimento\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
