{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "from utility_face_detection import face_detection, TrainDataset\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "from network_files import my_utility as mu\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source_dir, train_dir, test_dir, train_ratio=0.8):\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "    \n",
    "    \n",
    "    for category in os.listdir(source_dir):\n",
    "        category_path = os.path.join(source_dir, category)\n",
    "        \n",
    "        if os.path.isdir(category_path):\n",
    "            images = os.listdir(category_path)\n",
    "            random.seed(42)\n",
    "            random.shuffle(images)\n",
    "            \n",
    "            train_size = int(len(images) * train_ratio)\n",
    "            \n",
    "            train_images = images[:train_size]\n",
    "            test_images = images[train_size:]\n",
    "            \n",
    "            train_category_dir = os.path.join(train_dir, category)\n",
    "            test_category_dir = os.path.join(test_dir, category)\n",
    "            \n",
    "            if not os.path.exists(train_category_dir):\n",
    "                os.makedirs(train_category_dir)\n",
    "            if not os.path.exists(test_category_dir):\n",
    "                os.makedirs(test_category_dir)\n",
    "            \n",
    "            for image in train_images:\n",
    "                image_crop = face_detection(category_path + \"\\\\\" + image)\n",
    "                dst = os.path.join(train_category_dir, image[:11])\n",
    "                cv2.imwrite(dst  + '.jpg', image_crop)\n",
    "            \n",
    "            for image in test_images:\n",
    "                src = os.path.join(category_path, image)\n",
    "                dst = os.path.join(test_category_dir, image)\n",
    "                shutil.copy(src, dst)\n",
    "    \n",
    "    print(\"Splitting eseguito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codify_train_images(train_images):\n",
    "    model = mu.SiameseNeuralNetwork()\n",
    "    model_path = torch.load(f=\"model_all_images\")\n",
    "    model.load_state_dict(model_path)\n",
    "    model.eval()\n",
    "    with open(\"template.csv\", \"w\", newline=\"\") as template:\n",
    "        writer = csv.writer(template, delimiter=\";\")\n",
    "        for i in range(1,25):\n",
    "            train_curr_images = train_images + \"\\\\\" + str(i).rjust(2,'0')\n",
    "            images = TrainDataset(img_dir=train_curr_images)\n",
    "            img_dataloader = DataLoader(images, batch_size=1, drop_last=True)\n",
    "            for image in img_dataloader:\n",
    "                to_write = list(model(image).cpu().detach().numpy().flatten())\n",
    "                writer.writerow([to_write, str(i).rjust(2,'0')])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "torch.Size([175, 1, 128, 128])\n",
      "175\n",
      "Data loaded.\n",
      "torch.Size([187, 1, 128, 128])\n",
      "187\n",
      "Data loaded.\n",
      "torch.Size([265, 1, 128, 128])\n",
      "265\n",
      "Data loaded.\n",
      "torch.Size([249, 1, 128, 128])\n",
      "249\n",
      "Data loaded.\n",
      "torch.Size([484, 1, 128, 128])\n",
      "484\n",
      "Data loaded.\n",
      "torch.Size([239, 1, 128, 128])\n",
      "239\n",
      "Data loaded.\n",
      "torch.Size([280, 1, 128, 128])\n",
      "280\n",
      "Data loaded.\n",
      "torch.Size([404, 1, 128, 128])\n",
      "404\n",
      "Data loaded.\n",
      "torch.Size([379, 1, 128, 128])\n",
      "379\n",
      "Data loaded.\n",
      "torch.Size([250, 1, 128, 128])\n",
      "250\n",
      "Data loaded.\n",
      "torch.Size([347, 1, 128, 128])\n",
      "347\n",
      "Data loaded.\n",
      "torch.Size([465, 1, 128, 128])\n",
      "465\n",
      "Data loaded.\n",
      "torch.Size([344, 1, 128, 128])\n",
      "344\n",
      "Data loaded.\n",
      "torch.Size([201, 1, 128, 128])\n",
      "201\n",
      "Data loaded.\n",
      "torch.Size([232, 1, 128, 128])\n",
      "232\n",
      "Data loaded.\n",
      "torch.Size([334, 1, 128, 128])\n",
      "334\n",
      "Data loaded.\n",
      "torch.Size([195, 1, 128, 128])\n",
      "195\n",
      "Data loaded.\n",
      "torch.Size([154, 1, 128, 128])\n",
      "154\n",
      "Data loaded.\n",
      "torch.Size([73, 1, 128, 128])\n",
      "73\n",
      "Data loaded.\n",
      "torch.Size([300, 1, 128, 128])\n",
      "300\n",
      "Data loaded.\n",
      "torch.Size([86, 1, 128, 128])\n",
      "86\n",
      "Data loaded.\n",
      "torch.Size([342, 1, 128, 128])\n",
      "342\n",
      "Data loaded.\n",
      "torch.Size([192, 1, 128, 128])\n",
      "192\n",
      "Data loaded.\n",
      "torch.Size([172, 1, 128, 128])\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "source_directory = 'C:\\\\Users\\\\antho\\\\Desktop\\\\faceDetection\\\\face_images'\n",
    "\n",
    "train_directory = 'C:\\\\Users\\\\antho\\\\Desktop\\\\faceDetection\\\\dataset_splitted\\\\train'\n",
    "test_directory = 'C:\\\\Users\\\\antho\\\\Desktop\\\\faceDetection\\\\dataset_splitted\\\\test'\n",
    "\n",
    "\n",
    "codify_train_images(train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(source_directory, train_directory, test_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
